{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, intermediate_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_layer = tf.keras.layers.Dense(\n",
    "            units=intermediate_dim,\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer='he_uniform'\n",
    "            )\n",
    "        \n",
    "        self.output_layer = tf.keras.layers.Dense(\n",
    "            units=intermediate_dim,\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer='he_uniform'\n",
    "            )\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        activation = self.hidden_layer(input_features)\n",
    "        return self.output_layer(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, intermediate_dim, original_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_layer = tf.keras.layers.Dense(\n",
    "            units=intermediate_dim,\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer='he_uniform'\n",
    "            )\n",
    "        \n",
    "        self.output_layer = tf.keras.layers.Dense(\n",
    "            units=original_dim,\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer='he_uniform'\n",
    "            )\n",
    "        \n",
    "    def call(self, code):\n",
    "        activation = self.hidden_layer(code)\n",
    "        return self.output_layer(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, intermediate_dim, original_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(intermediate_dim=intermediate_dim)\n",
    "        self.decoder = Decoder(intermediate_dim=intermediate_dim, original_dim=original_dim)\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        code = self.encoder(input_features)\n",
    "        reconstructed = self.decoder(code)\n",
    "        return reconstructed\n",
    "\n",
    "def loss(model, original):\n",
    "    reconstruction_error = tf.reduce_mean(tf.square(tf.subtract(model(original), original)))\n",
    "    return reconstruction_error\n",
    "def train(loss, model, opt, original):\n",
    "    with tf.GradientTape() as tape:\n",
    "        gradients = tape.gradient(loss(model, original), model.trainable_variables)\n",
    "        gradient_variables = zip(gradients, model.trainable_variables)\n",
    "        opt.apply_gradients(gradient_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(intermediate_dim=64,\n",
    "                         original_dim=784)\n",
    "batch_size = 1024\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "opt = tf.optimizers.Adam(learning_rate=0.001, decay=0.01)\n",
    "\n",
    "(training_features, _), (test_features, _) = tf.keras.datasets.mnist.load_data()\n",
    "training_features = training_features / np.max(training_features)\n",
    "training_features = training_features.reshape(training_features.shape[0],\n",
    "                                              training_features.shape[1] * training_features.shape[2])\n",
    "training_features = training_features.astype('float32')\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices(training_features)\n",
    "training_dataset = training_dataset.batch(batch_size)\n",
    "training_dataset = training_dataset.shuffle(training_features.shape[0])\n",
    "training_dataset = training_dataset.prefetch(batch_size * 4)\n",
    "\n",
    "writer = tf.summary.create_file_writer('tmp')\n",
    "\n",
    "with writer.as_default():\n",
    "    with tf.summary.record_if(True):\n",
    "        for epoch in range(epochs):\n",
    "              for step, batch_features in enumerate(training_dataset):\n",
    "                train(loss, autoencoder, opt, batch_features)\n",
    "                loss_values = loss(autoencoder, batch_features)\n",
    "                original = tf.reshape(batch_features, (batch_features.shape[0], 28, 28, 1))\n",
    "                reconstructed = tf.reshape(autoencoder(tf.constant(batch_features)), (batch_features.shape[0], 28, 28, 1))\n",
    "                tf.summary.scalar('loss', loss_values, step=step)\n",
    "                tf.summary.image('original', original, max_outputs=10, step=step)\n",
    "                tf.summary.image('reconstructed', reconstructed, max_outputs=10, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir tmp/ --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
