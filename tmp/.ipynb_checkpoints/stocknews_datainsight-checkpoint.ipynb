{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RedditNews.csv', 'Combined_News_DJIA.csv', 'upload_DJIA_table.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data/stocknews/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reddit = pd.read_csv('../data/stocknews/RedditNews.csv')\n",
    "df_news = pd.read_csv('../data/stocknews/Combined_News_DJIA.csv')\n",
    "df_djia = pd.read_csv('../data/stocknews/upload_DJIA_table.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_djia_news = pd.merge(df_djia, df_news, on='Date', how='inner')\n",
    "\n",
    "df = pd.merge(df_djia_news, df_reddit, on='Date', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A 117-year-old woman in Mexico City finally received her birth certificate, and died a few hours later. Trinidad Alvarez Lira had waited years for proof that she had been born in 1898.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_djia_news['Top1'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1213c8a58>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0 = decrease , 1 = increase or equal at Adj.Close\n",
    "sns.countplot(x='Label', data=df_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess \n",
    "def preprocess_text(sen):\n",
    "    sentence = remove_tags(sen)\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"Georgia \\'downs two Russian warplanes\\' as countries move to brink of war\"'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['Top1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list()\n",
    "sentences = df_news['Top1']\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))\n",
    "    \n",
    "y = df_news['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch glove.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_file = open('glove.txt', dtype='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-db60d4e48ae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membedding_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-9d9fdc2a0a74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized keyword arguments: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2882\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2883\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2884\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2885\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
